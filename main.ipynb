{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416ddf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0\n",
      "MPS Available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"MPS Available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42a70f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "x = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight*x + bias\n",
    "\n",
    "x[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c3d6ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "train_split = int(0.8*len(x))\n",
    "x_train, y_train = x[:train_split], y[:train_split]\n",
    "x_test, y_test = x[train_split:], y[train_split:]\n",
    "\n",
    "for i in [x_train, y_train, x_test, y_test]:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915e5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions(train_data=x_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=x_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "  plt.scatter(test_data, test_labels, c=\"r\", s=4, label=\"Testing data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa2dfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79646996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, dtype=torch.float),requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(1,dtype=torch.float), requires_grad=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x +  self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52cc0881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0 = LinearRegression()\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35b2d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds = model_0(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4266da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of testing samples: 10\n",
      "No. of predictions made: 10\n",
      "Predicted Values: tensor([[0.3982],\n",
      "        [0.4049],\n",
      "        [0.4116],\n",
      "        [0.4184],\n",
      "        [0.4251],\n",
      "        [0.4318],\n",
      "        [0.4386],\n",
      "        [0.4453],\n",
      "        [0.4520],\n",
      "        [0.4588]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"No. of testing samples: {len(x_test)}\")\n",
    "print(f\"No. of predictions made: {len(y_preds)}\")\n",
    "print(f\"Predicted Values: {y_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab58a91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1e60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afd73a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train loss: 0.31288135051727295 | MAE Test loss: 0.47563618421554565\n",
      "Epoch: 10 | MAE Train loss: 0.17388133704662323 | MAE Test loss: 0.28663620352745056\n",
      "Epoch: 20 | MAE Train loss: 0.042198799550533295 | MAE Test loss: 0.0987466350197792\n",
      "Epoch: 30 | MAE Train loss: 0.044207725673913956 | MAE Test loss: 0.005456477403640747\n",
      "Epoch: 40 | MAE Train loss: 0.022640462964773178 | MAE Test loss: 0.0635034590959549\n",
      "Epoch: 50 | MAE Train loss: 0.017085563391447067 | MAE Test loss: 0.0409594364464283\n",
      "Epoch: 60 | MAE Train loss: 0.008707200177013874 | MAE Test loss: 0.013333290815353394\n",
      "Epoch: 70 | MAE Train loss: 0.0023071214091032743 | MAE Test loss: 0.002345192478969693\n",
      "Epoch: 80 | MAE Train loss: 0.0022460990585386753 | MAE Test loss: 0.002025943947955966\n",
      "Epoch: 90 | MAE Train loss: 0.0018262952798977494 | MAE Test loss: 0.0037562549114227295\n",
      "Epoch: 100 | MAE Train loss: 0.002000708132982254 | MAE Test loss: 0.0017548144096508622\n",
      "Epoch: 110 | MAE Train loss: 0.0014610119396820664 | MAE Test loss: 0.0009593426948413253\n",
      "Epoch: 120 | MAE Train loss: 0.0014272518455982208 | MAE Test loss: 0.0006734252092428505\n",
      "Epoch: 130 | MAE Train loss: 0.004037574864923954 | MAE Test loss: 0.00542785506695509\n",
      "Epoch: 140 | MAE Train loss: 0.0025618828367441893 | MAE Test loss: 0.0005454421043395996\n",
      "Epoch: 150 | MAE Train loss: 0.0027290680445730686 | MAE Test loss: 0.004743444733321667\n",
      "Epoch: 160 | MAE Train loss: 0.004244360141456127 | MAE Test loss: 0.004322922322899103\n",
      "Epoch: 170 | MAE Train loss: 0.00032307131914421916 | MAE Test loss: 0.00019982457160949707\n",
      "Epoch: 180 | MAE Train loss: 0.0006539806490764022 | MAE Test loss: 0.0008662641048431396\n",
      "Epoch: 190 | MAE Train loss: 0.0015434973174706101 | MAE Test loss: 0.0018310189479961991\n",
      "Epoch: 200 | MAE Train loss: 0.00036412180634215474 | MAE Test loss: 0.0004741966840811074\n",
      "Epoch: 210 | MAE Train loss: 0.0012166969245299697 | MAE Test loss: 0.0015355944633483887\n",
      "Epoch: 220 | MAE Train loss: 0.00068021344486624 | MAE Test loss: 0.0007313251262530684\n",
      "Epoch: 230 | MAE Train loss: 0.0010838523739948869 | MAE Test loss: 0.0014198959106579423\n",
      "Epoch: 240 | MAE Train loss: 0.0007047526305541396 | MAE Test loss: 0.0007470905547961593\n",
      "Epoch: 250 | MAE Train loss: 0.0010563053656369448 | MAE Test loss: 0.0013926863903179765\n",
      "Epoch: 260 | MAE Train loss: 0.0006972200935706496 | MAE Test loss: 0.0007371187093667686\n",
      "Epoch: 270 | MAE Train loss: 0.00104335171636194 | MAE Test loss: 0.0013784170150756836\n",
      "Epoch: 280 | MAE Train loss: 0.0006876781699247658 | MAE Test loss: 0.0007259786361828446\n",
      "Epoch: 290 | MAE Train loss: 0.001033832086250186 | MAE Test loss: 0.0013675630325451493\n",
      "Epoch: 300 | MAE Train loss: 0.000679203134495765 | MAE Test loss: 0.0007163226837292314\n",
      "Epoch: 310 | MAE Train loss: 0.0010259352857246995 | MAE Test loss: 0.001358544803224504\n",
      "Epoch: 320 | MAE Train loss: 0.0006719439988955855 | MAE Test loss: 0.0007080614450387657\n",
      "Epoch: 330 | MAE Train loss: 0.0010192468762397766 | MAE Test loss: 0.001350826001726091\n",
      "Epoch: 340 | MAE Train loss: 0.000665675092022866 | MAE Test loss: 0.0007008671527728438\n",
      "Epoch: 350 | MAE Train loss: 0.0010134174954146147 | MAE Test loss: 0.0013440668117254972\n",
      "Epoch: 360 | MAE Train loss: 0.0006602659705094993 | MAE Test loss: 0.0006947338697500527\n",
      "Epoch: 370 | MAE Train loss: 0.0010083287488669157 | MAE Test loss: 0.0013382375473156571\n",
      "Epoch: 380 | MAE Train loss: 0.0006554446881636977 | MAE Test loss: 0.000689131033141166\n",
      "Epoch: 390 | MAE Train loss: 0.0010038666659966111 | MAE Test loss: 0.0013330995570868254\n",
      "Epoch: 400 | MAE Train loss: 0.0006512820837087929 | MAE Test loss: 0.0006843626615591347\n",
      "Epoch: 410 | MAE Train loss: 0.000999935669824481 | MAE Test loss: 0.0013285696040838957\n",
      "Epoch: 420 | MAE Train loss: 0.000647508364636451 | MAE Test loss: 0.000680088996887207\n",
      "Epoch: 430 | MAE Train loss: 0.0009963579941540956 | MAE Test loss: 0.0013244092697277665\n",
      "Epoch: 440 | MAE Train loss: 0.0006441697478294373 | MAE Test loss: 0.0006762564298696816\n",
      "Epoch: 450 | MAE Train loss: 0.000993122928775847 | MAE Test loss: 0.0013206719886511564\n",
      "Epoch: 460 | MAE Train loss: 0.0006411403301171958 | MAE Test loss: 0.000672757625579834\n",
      "Epoch: 470 | MAE Train loss: 0.0009902671445161104 | MAE Test loss: 0.0013173759216442704\n",
      "Epoch: 480 | MAE Train loss: 0.0006384208681993186 | MAE Test loss: 0.0006696224445477128\n",
      "Epoch: 490 | MAE Train loss: 0.0009876042604446411 | MAE Test loss: 0.0013142407406121492\n",
      "Epoch: 500 | MAE Train loss: 0.0006359309190884233 | MAE Test loss: 0.0006668030982837081\n",
      "Epoch: 510 | MAE Train loss: 0.0009852752555161715 | MAE Test loss: 0.0013116300106048584\n",
      "Epoch: 520 | MAE Train loss: 0.0006335817161016166 | MAE Test loss: 0.0006640970823355019\n",
      "Epoch: 530 | MAE Train loss: 0.0009830951457843184 | MAE Test loss: 0.0013090670108795166\n",
      "Epoch: 540 | MAE Train loss: 0.0006314657512120903 | MAE Test loss: 0.0006616592290811241\n",
      "Epoch: 550 | MAE Train loss: 0.000981158809736371 | MAE Test loss: 0.0013068377738818526\n",
      "Epoch: 560 | MAE Train loss: 0.0006294466438703239 | MAE Test loss: 0.0006592929130420089\n",
      "Epoch: 570 | MAE Train loss: 0.0009794473880901933 | MAE Test loss: 0.0013048291439190507\n",
      "Epoch: 580 | MAE Train loss: 0.0006275892374105752 | MAE Test loss: 0.0006571829435415566\n",
      "Epoch: 590 | MAE Train loss: 0.0009777076775208116 | MAE Test loss: 0.0013028383255004883\n",
      "Epoch: 600 | MAE Train loss: 0.000625915068667382 | MAE Test loss: 0.0006552338600158691\n",
      "Epoch: 610 | MAE Train loss: 0.000976160925347358 | MAE Test loss: 0.0013010561233386397\n",
      "Epoch: 620 | MAE Train loss: 0.0006243929383344948 | MAE Test loss: 0.0006534695858135819\n",
      "Epoch: 630 | MAE Train loss: 0.0009746506693772972 | MAE Test loss: 0.0012993097770959139\n",
      "Epoch: 640 | MAE Train loss: 0.0006230316939763725 | MAE Test loss: 0.0006518781301565468\n",
      "Epoch: 650 | MAE Train loss: 0.0009733043843880296 | MAE Test loss: 0.0012977540027350187\n",
      "Epoch: 660 | MAE Train loss: 0.0006217352929525077 | MAE Test loss: 0.0006503939512185752\n",
      "Epoch: 670 | MAE Train loss: 0.0009719908121041954 | MAE Test loss: 0.0012961924076080322\n",
      "Epoch: 680 | MAE Train loss: 0.0006205484387464821 | MAE Test loss: 0.000649052846711129\n",
      "Epoch: 690 | MAE Train loss: 0.000970754015725106 | MAE Test loss: 0.001294809626415372\n",
      "Epoch: 700 | MAE Train loss: 0.0006193466251716018 | MAE Test loss: 0.0006476462003774941\n",
      "Epoch: 710 | MAE Train loss: 0.0009695857879705727 | MAE Test loss: 0.0012934028636664152\n",
      "Epoch: 720 | MAE Train loss: 0.0006183109944686294 | MAE Test loss: 0.000646442174911499\n",
      "Epoch: 730 | MAE Train loss: 0.0009685762342996895 | MAE Test loss: 0.00129224662669003\n",
      "Epoch: 740 | MAE Train loss: 0.0006172314169816673 | MAE Test loss: 0.0006452500820159912\n",
      "Epoch: 750 | MAE Train loss: 0.0009675942128524184 | MAE Test loss: 0.00129108433611691\n",
      "Epoch: 760 | MAE Train loss: 0.0006163067882880569 | MAE Test loss: 0.0006441652658395469\n",
      "Epoch: 770 | MAE Train loss: 0.0009666926926001906 | MAE Test loss: 0.0012900412548333406\n",
      "Epoch: 780 | MAE Train loss: 0.0006152935093268752 | MAE Test loss: 0.0006430208450183272\n",
      "Epoch: 790 | MAE Train loss: 0.0009658850613050163 | MAE Test loss: 0.0012890935176983476\n",
      "Epoch: 800 | MAE Train loss: 0.0006144650396890938 | MAE Test loss: 0.0006420373683795333\n",
      "Epoch: 810 | MAE Train loss: 0.0009649366256780922 | MAE Test loss: 0.0012879669666290283\n",
      "Epoch: 820 | MAE Train loss: 0.0006137207383289933 | MAE Test loss: 0.00064125657081604\n",
      "Epoch: 830 | MAE Train loss: 0.0009641557699069381 | MAE Test loss: 0.001287049031816423\n",
      "Epoch: 840 | MAE Train loss: 0.0006129659595899284 | MAE Test loss: 0.0006403207662515342\n",
      "Epoch: 850 | MAE Train loss: 0.0009633965673856437 | MAE Test loss: 0.001286196755245328\n",
      "Epoch: 860 | MAE Train loss: 0.0006122663617134094 | MAE Test loss: 0.0006395220989361405\n",
      "Epoch: 870 | MAE Train loss: 0.0009626753744669259 | MAE Test loss: 0.0012853086227551103\n",
      "Epoch: 880 | MAE Train loss: 0.0006115458672866225 | MAE Test loss: 0.0006386935710906982\n",
      "Epoch: 890 | MAE Train loss: 0.0009619869524613023 | MAE Test loss: 0.001284605241380632\n",
      "Epoch: 900 | MAE Train loss: 0.0006109572714194655 | MAE Test loss: 0.0006379783153533936\n",
      "Epoch: 910 | MAE Train loss: 0.0009613387519493699 | MAE Test loss: 0.0012838601833209395\n",
      "Epoch: 920 | MAE Train loss: 0.0006103210034780204 | MAE Test loss: 0.0006372153875418007\n",
      "Epoch: 930 | MAE Train loss: 0.0009606935200281441 | MAE Test loss: 0.0012830793857574463\n",
      "Epoch: 940 | MAE Train loss: 0.0006097041186876595 | MAE Test loss: 0.0006364703294821084\n",
      "Epoch: 950 | MAE Train loss: 0.0009601071360521019 | MAE Test loss: 0.0012823879951611161\n",
      "Epoch: 960 | MAE Train loss: 0.0006091684335842729 | MAE Test loss: 0.0006358802202157676\n",
      "Epoch: 970 | MAE Train loss: 0.0009595424053259194 | MAE Test loss: 0.0012817621463909745\n",
      "Epoch: 980 | MAE Train loss: 0.0006086662178859115 | MAE Test loss: 0.0006353378412313759\n",
      "Epoch: 990 | MAE Train loss: 0.000958984368480742 | MAE Test loss: 0.0012811243068426847\n",
      "Epoch: 1000 | MAE Train loss: 0.0006081618485040963 | MAE Test loss: 0.0006347179296426475\n",
      "Epoch: 1010 | MAE Train loss: 0.0009583972278051078 | MAE Test loss: 0.00128040905110538\n",
      "Epoch: 1020 | MAE Train loss: 0.0006077095749787986 | MAE Test loss: 0.0006341874832287431\n",
      "Epoch: 1030 | MAE Train loss: 0.0009579442557878792 | MAE Test loss: 0.001279932213947177\n",
      "Epoch: 1040 | MAE Train loss: 0.0006072648102417588 | MAE Test loss: 0.0006336510414257646\n",
      "Epoch: 1050 | MAE Train loss: 0.0009575001895427704 | MAE Test loss: 0.0012793720234185457\n",
      "Epoch: 1060 | MAE Train loss: 0.0006067886715754867 | MAE Test loss: 0.000633114599622786\n",
      "Epoch: 1070 | MAE Train loss: 0.0009570263209752738 | MAE Test loss: 0.0012788355816155672\n",
      "Epoch: 1080 | MAE Train loss: 0.0006063416367396712 | MAE Test loss: 0.0006326138973236084\n",
      "Epoch: 1090 | MAE Train loss: 0.0009566053631715477 | MAE Test loss: 0.0012783228885382414\n",
      "Epoch: 1100 | MAE Train loss: 0.0006059653824195266 | MAE Test loss: 0.0006322145345620811\n",
      "Epoch: 1110 | MAE Train loss: 0.0009561747428961098 | MAE Test loss: 0.0012777925003319979\n",
      "Epoch: 1120 | MAE Train loss: 0.0006055690464563668 | MAE Test loss: 0.0006318092346191406\n",
      "Epoch: 1130 | MAE Train loss: 0.0009557761368341744 | MAE Test loss: 0.0012773096095770597\n",
      "Epoch: 1140 | MAE Train loss: 0.0006052315002307296 | MAE Test loss: 0.0006314039346762002\n",
      "Epoch: 1150 | MAE Train loss: 0.0009553820127621293 | MAE Test loss: 0.0012768327724188566\n",
      "Epoch: 1160 | MAE Train loss: 0.0006048314389772713 | MAE Test loss: 0.0006309509044513106\n",
      "Epoch: 1170 | MAE Train loss: 0.0009550497052259743 | MAE Test loss: 0.0012764036655426025\n",
      "Epoch: 1180 | MAE Train loss: 0.0006044678157195449 | MAE Test loss: 0.0006305754068307579\n",
      "Epoch: 1190 | MAE Train loss: 0.0009546928340569139 | MAE Test loss: 0.0012760102981701493\n",
      "Epoch: 1200 | MAE Train loss: 0.0006041548913344741 | MAE Test loss: 0.00063024164410308\n",
      "Epoch: 1210 | MAE Train loss: 0.0009543612832203507 | MAE Test loss: 0.0012755930656567216\n",
      "Epoch: 1220 | MAE Train loss: 0.00060387107077986 | MAE Test loss: 0.0006298840162344277\n",
      "Epoch: 1230 | MAE Train loss: 0.0009540490573272109 | MAE Test loss: 0.0012752473121508956\n",
      "Epoch: 1240 | MAE Train loss: 0.000603511172812432 | MAE Test loss: 0.000629466783721\n",
      "Epoch: 1250 | MAE Train loss: 0.0009536862489767373 | MAE Test loss: 0.0012748539447784424\n",
      "Epoch: 1260 | MAE Train loss: 0.0006032407400198281 | MAE Test loss: 0.0006291210884228349\n",
      "Epoch: 1270 | MAE Train loss: 0.0009533740812912583 | MAE Test loss: 0.001274448586627841\n",
      "Epoch: 1280 | MAE Train loss: 0.0006030023214407265 | MAE Test loss: 0.0006289005395956337\n",
      "Epoch: 1290 | MAE Train loss: 0.0009529896196909249 | MAE Test loss: 0.0012739419471472502\n",
      "Epoch: 1300 | MAE Train loss: 0.0006027519702911377 | MAE Test loss: 0.0006285965209826827\n",
      "Epoch: 1310 | MAE Train loss: 0.0009527556831017137 | MAE Test loss: 0.001273763133212924\n",
      "Epoch: 1320 | MAE Train loss: 0.0006024271133355796 | MAE Test loss: 0.0006281733512878418\n",
      "Epoch: 1330 | MAE Train loss: 0.0009525172645226121 | MAE Test loss: 0.0012735665077343583\n",
      "Epoch: 1340 | MAE Train loss: 0.0006021313602104783 | MAE Test loss: 0.0006277799839153886\n",
      "Epoch: 1350 | MAE Train loss: 0.0009522795444354415 | MAE Test loss: 0.0012732207542285323\n",
      "Epoch: 1360 | MAE Train loss: 0.0006019793218001723 | MAE Test loss: 0.0006276607746258378\n",
      "Epoch: 1370 | MAE Train loss: 0.0009519703453406692 | MAE Test loss: 0.0012728155124932528\n",
      "Epoch: 1380 | MAE Train loss: 0.0006017021951265633 | MAE Test loss: 0.0006272971513681114\n",
      "Epoch: 1390 | MAE Train loss: 0.0009517163271084428 | MAE Test loss: 0.0012726008426398039\n",
      "Epoch: 1400 | MAE Train loss: 0.0006015315884724259 | MAE Test loss: 0.0006271779420785606\n",
      "Epoch: 1410 | MAE Train loss: 0.0009514965349808335 | MAE Test loss: 0.001272314810194075\n",
      "Epoch: 1420 | MAE Train loss: 0.0006012812373228371 | MAE Test loss: 0.0006268203142099082\n",
      "Epoch: 1430 | MAE Train loss: 0.0009512409451417625 | MAE Test loss: 0.001272010849788785\n",
      "Epoch: 1440 | MAE Train loss: 0.0006010539946146309 | MAE Test loss: 0.0006265759584493935\n",
      "Epoch: 1450 | MAE Train loss: 0.0009510472300462425 | MAE Test loss: 0.001271754503250122\n",
      "Epoch: 1460 | MAE Train loss: 0.0006007969495840371 | MAE Test loss: 0.0006262898677960038\n",
      "Epoch: 1470 | MAE Train loss: 0.0009508713847026229 | MAE Test loss: 0.0012715875636786222\n",
      "Epoch: 1480 | MAE Train loss: 0.0006006009643897414 | MAE Test loss: 0.0006260931259021163\n",
      "Epoch: 1490 | MAE Train loss: 0.0009506590431556106 | MAE Test loss: 0.001271325396373868\n",
      "Epoch: 1500 | MAE Train loss: 0.0006004072492942214 | MAE Test loss: 0.0006258785724639893\n",
      "Epoch: 1510 | MAE Train loss: 0.0009504318004474044 | MAE Test loss: 0.001271063112653792\n",
      "Epoch: 1520 | MAE Train loss: 0.0006002135341987014 | MAE Test loss: 0.0006256103515625\n",
      "Epoch: 1530 | MAE Train loss: 0.0009502664324827492 | MAE Test loss: 0.0012708365684375167\n",
      "Epoch: 1540 | MAE Train loss: 0.0006000384455546737 | MAE Test loss: 0.000625437474809587\n",
      "Epoch: 1550 | MAE Train loss: 0.000950039189774543 | MAE Test loss: 0.0012705862754955888\n",
      "Epoch: 1560 | MAE Train loss: 0.0005998752894811332 | MAE Test loss: 0.00062522292137146\n",
      "Epoch: 1570 | MAE Train loss: 0.0009498983854427934 | MAE Test loss: 0.0012704133987426758\n",
      "Epoch: 1580 | MAE Train loss: 0.0005996517720632255 | MAE Test loss: 0.000624924898147583\n",
      "Epoch: 1590 | MAE Train loss: 0.0009497329592704773 | MAE Test loss: 0.0012702643871307373\n",
      "Epoch: 1600 | MAE Train loss: 0.0005994833773002028 | MAE Test loss: 0.0006248056888580322\n",
      "Epoch: 1610 | MAE Train loss: 0.0009495384874753654 | MAE Test loss: 0.0012700200313702226\n",
      "Epoch: 1620 | MAE Train loss: 0.0005993180093355477 | MAE Test loss: 0.0006245672702789307\n",
      "Epoch: 1630 | MAE Train loss: 0.0009493604302406311 | MAE Test loss: 0.0012698471546173096\n",
      "Epoch: 1640 | MAE Train loss: 0.0005991540965624154 | MAE Test loss: 0.00062436459120363\n",
      "Epoch: 1650 | MAE Train loss: 0.0009492233511991799 | MAE Test loss: 0.0012696683406829834\n",
      "Epoch: 1660 | MAE Train loss: 0.0005990453064441681 | MAE Test loss: 0.0006241977098397911\n",
      "Epoch: 1670 | MAE Train loss: 0.0009490504744462669 | MAE Test loss: 0.0012694299221038818\n",
      "Epoch: 1680 | MAE Train loss: 0.0005989551427774131 | MAE Test loss: 0.0006241381051950157\n",
      "Epoch: 1690 | MAE Train loss: 0.0009488232317380607 | MAE Test loss: 0.0012692153686657548\n",
      "Epoch: 1700 | MAE Train loss: 0.0005988210323266685 | MAE Test loss: 0.0006239473586902022\n",
      "Epoch: 1710 | MAE Train loss: 0.0009487114730291069 | MAE Test loss: 0.0012690722942352295\n",
      "Epoch: 1720 | MAE Train loss: 0.0005986563628539443 | MAE Test loss: 0.0006237804773263633\n",
      "Epoch: 1730 | MAE Train loss: 0.0009485438349656761 | MAE Test loss: 0.0012689292198047042\n",
      "Epoch: 1740 | MAE Train loss: 0.0005985371535643935 | MAE Test loss: 0.0006236851331777871\n",
      "Epoch: 1750 | MAE Train loss: 0.0009483836474828422 | MAE Test loss: 0.0012687027920037508\n",
      "Epoch: 1760 | MAE Train loss: 0.0005984455347061157 | MAE Test loss: 0.0006235897308215499\n",
      "Epoch: 1770 | MAE Train loss: 0.0009482167661190033 | MAE Test loss: 0.0012684643734246492\n",
      "Epoch: 1780 | MAE Train loss: 0.0005983263254165649 | MAE Test loss: 0.0006234705215319991\n",
      "Epoch: 1790 | MAE Train loss: 0.0009480603039264679 | MAE Test loss: 0.0012682497035712004\n",
      "Epoch: 1800 | MAE Train loss: 0.0005982182919979095 | MAE Test loss: 0.0006233513122424483\n",
      "Epoch: 1810 | MAE Train loss: 0.0009480022126808763 | MAE Test loss: 0.001268190098926425\n",
      "Epoch: 1820 | MAE Train loss: 0.0005980774876661599 | MAE Test loss: 0.0006231606239452958\n",
      "Epoch: 1830 | MAE Train loss: 0.0009478889405727386 | MAE Test loss: 0.0012680410873144865\n",
      "Epoch: 1840 | MAE Train loss: 0.0005979880806989968 | MAE Test loss: 0.0006230771541595459\n",
      "Epoch: 1850 | MAE Train loss: 0.0009477175772190094 | MAE Test loss: 0.0012678622733801603\n",
      "Epoch: 1860 | MAE Train loss: 0.0005978777771815658 | MAE Test loss: 0.0006229579448699951\n",
      "Epoch: 1870 | MAE Train loss: 0.0009475521510466933 | MAE Test loss: 0.0012676238548010588\n",
      "Epoch: 1880 | MAE Train loss: 0.0005977965774945915 | MAE Test loss: 0.000622910272795707\n",
      "Epoch: 1890 | MAE Train loss: 0.0009474769467487931 | MAE Test loss: 0.0012675464386120439\n",
      "Epoch: 1900 | MAE Train loss: 0.0005976826068945229 | MAE Test loss: 0.0006227612611837685\n",
      "Epoch: 1910 | MAE Train loss: 0.000947304826695472 | MAE Test loss: 0.0012673496967181563\n",
      "Epoch: 1920 | MAE Train loss: 0.0005976587417535484 | MAE Test loss: 0.0006227195262908936\n",
      "Epoch: 1930 | MAE Train loss: 0.0009470991790294647 | MAE Test loss: 0.0012671410804614425\n",
      "Epoch: 1940 | MAE Train loss: 0.0005975440144538879 | MAE Test loss: 0.0006226003170013428\n",
      "Epoch: 1950 | MAE Train loss: 0.000947076827287674 | MAE Test loss: 0.0012670934665948153\n",
      "Epoch: 1960 | MAE Train loss: 0.0005973734077997506 | MAE Test loss: 0.0006223976379260421\n",
      "Epoch: 1970 | MAE Train loss: 0.000947076827287674 | MAE Test loss: 0.0012670934665948153\n",
      "Epoch: 1980 | MAE Train loss: 0.0005972571671009064 | MAE Test loss: 0.0006222546217031777\n",
      "Epoch: 1990 | MAE Train loss: 0.0009469144279137254 | MAE Test loss: 0.0012668787967413664\n",
      "Epoch: 2000 | MAE Train loss: 0.0005972392973490059 | MAE Test loss: 0.0006222307565622032\n",
      "Epoch: 2010 | MAE Train loss: 0.0009467266499996185 | MAE Test loss: 0.0012667179107666016\n",
      "Epoch: 2020 | MAE Train loss: 0.0005971267819404602 | MAE Test loss: 0.0006220638751983643\n",
      "Epoch: 2030 | MAE Train loss: 0.0009467266499996185 | MAE Test loss: 0.0012667179107666016\n",
      "Epoch: 2040 | MAE Train loss: 0.0005970209604129195 | MAE Test loss: 0.000621920800767839\n",
      "Epoch: 2050 | MAE Train loss: 0.0009466074407100677 | MAE Test loss: 0.0012665987014770508\n",
      "Epoch: 2060 | MAE Train loss: 0.0005969129269942641 | MAE Test loss: 0.0006217479822225869\n",
      "Epoch: 2070 | MAE Train loss: 0.0009465806069783866 | MAE Test loss: 0.0012665570247918367\n",
      "Epoch: 2080 | MAE Train loss: 0.0005968339974060655 | MAE Test loss: 0.0006216525798663497\n",
      "Epoch: 2090 | MAE Train loss: 0.000946488231420517 | MAE Test loss: 0.001266521168872714\n",
      "Epoch: 2100 | MAE Train loss: 0.0005967177567072213 | MAE Test loss: 0.0006215631728991866\n",
      "Epoch: 2110 | MAE Train loss: 0.0009463891619816422 | MAE Test loss: 0.0012664139503613114\n",
      "Epoch: 2120 | MAE Train loss: 0.0005966730532236397 | MAE Test loss: 0.0006215035682544112\n",
      "Epoch: 2130 | MAE Train loss: 0.0009463034803047776 | MAE Test loss: 0.0012662947410717607\n",
      "Epoch: 2140 | MAE Train loss: 0.000596581376157701 | MAE Test loss: 0.0006213843589648604\n",
      "Epoch: 2150 | MAE Train loss: 0.0009462207672186196 | MAE Test loss: 0.0012661755317822099\n",
      "Epoch: 2160 | MAE Train loss: 0.0005965314921922982 | MAE Test loss: 0.0006213068845681846\n",
      "Epoch: 2170 | MAE Train loss: 0.000946170068345964 | MAE Test loss: 0.0012661159271374345\n",
      "Epoch: 2180 | MAE Train loss: 0.0005964472657069564 | MAE Test loss: 0.0006212472799234092\n",
      "Epoch: 2190 | MAE Train loss: 0.000946059066336602 | MAE Test loss: 0.0012659967178478837\n",
      "Epoch: 2200 | MAE Train loss: 0.0005963578587397933 | MAE Test loss: 0.0006211340660229325\n",
      "Epoch: 2210 | MAE Train loss: 0.0009459674474783242 | MAE Test loss: 0.0012659013736993074\n",
      "Epoch: 2220 | MAE Train loss: 0.0005963399889878929 | MAE Test loss: 0.000621110200881958\n",
      "Epoch: 2230 | MAE Train loss: 0.0009458705899305642 | MAE Test loss: 0.0012657821644097567\n",
      "Epoch: 2240 | MAE Train loss: 0.0005962431314401329 | MAE Test loss: 0.0006210029241628945\n",
      "Epoch: 2250 | MAE Train loss: 0.0009458392742089927 | MAE Test loss: 0.0012656986946240067\n",
      "Epoch: 2260 | MAE Train loss: 0.000596186495386064 | MAE Test loss: 0.0006209194543771446\n",
      "Epoch: 2270 | MAE Train loss: 0.0009457513806410134 | MAE Test loss: 0.0012656629551202059\n",
      "Epoch: 2280 | MAE Train loss: 0.0005960859125480056 | MAE Test loss: 0.0006207764381542802\n",
      "Epoch: 2290 | MAE Train loss: 0.0009456753614358604 | MAE Test loss: 0.001265579485334456\n",
      "Epoch: 2300 | MAE Train loss: 0.0005960300331935287 | MAE Test loss: 0.000620681035798043\n",
      "Epoch: 2310 | MAE Train loss: 0.0009456321713514626 | MAE Test loss: 0.0012655615573748946\n",
      "Epoch: 2320 | MAE Train loss: 0.000595971941947937 | MAE Test loss: 0.0006206214311532676\n",
      "Epoch: 2330 | MAE Train loss: 0.000945532345212996 | MAE Test loss: 0.0012654006714001298\n",
      "Epoch: 2340 | MAE Train loss: 0.0005959406262263656 | MAE Test loss: 0.0006205856916494668\n",
      "Epoch: 2350 | MAE Train loss: 0.0009454831597395241 | MAE Test loss: 0.0012653410667553544\n",
      "Epoch: 2360 | MAE Train loss: 0.0005958825349807739 | MAE Test loss: 0.0006205022218637168\n",
      "Epoch: 2370 | MAE Train loss: 0.0009453982347622514 | MAE Test loss: 0.0012652277946472168\n",
      "Epoch: 2380 | MAE Train loss: 0.0005958601832389832 | MAE Test loss: 0.000620466482359916\n",
      "Epoch: 2390 | MAE Train loss: 0.000945373612921685 | MAE Test loss: 0.00126523373182863\n",
      "Epoch: 2400 | MAE Train loss: 0.0005957797402516007 | MAE Test loss: 0.0006203949451446533\n",
      "Epoch: 2410 | MAE Train loss: 0.0009452573722228408 | MAE Test loss: 0.0012651145225390792\n",
      "Epoch: 2420 | MAE Train loss: 0.0005957275861874223 | MAE Test loss: 0.0006203592056408525\n",
      "Epoch: 2430 | MAE Train loss: 0.0009451702353544533 | MAE Test loss: 0.0012650310527533293\n",
      "Epoch: 2440 | MAE Train loss: 0.0005957275861874223 | MAE Test loss: 0.0006203592056408525\n",
      "Epoch: 2450 | MAE Train loss: 0.0009450875222682953 | MAE Test loss: 0.0012649118434637785\n",
      "Epoch: 2460 | MAE Train loss: 0.00059566053096205 | MAE Test loss: 0.0006203114753589034\n",
      "Epoch: 2470 | MAE Train loss: 0.0009450636571273208 | MAE Test loss: 0.0012648642295971513\n",
      "Epoch: 2480 | MAE Train loss: 0.0005956083768978715 | MAE Test loss: 0.0006202399963513017\n",
      "Epoch: 2490 | MAE Train loss: 0.0009450137731619179 | MAE Test loss: 0.0012647866969928145\n",
      "Epoch: 2500 | MAE Train loss: 0.0005955718224868178 | MAE Test loss: 0.0006202161312103271\n",
      "Epoch: 2510 | MAE Train loss: 0.000944951199926436 | MAE Test loss: 0.0012647270923480392\n",
      "Epoch: 2520 | MAE Train loss: 0.0005955465021543205 | MAE Test loss: 0.000620168459136039\n",
      "Epoch: 2530 | MAE Train loss: 0.0009449220960959792 | MAE Test loss: 0.0012646972900256515\n",
      "Epoch: 2540 | MAE Train loss: 0.0005954377120360732 | MAE Test loss: 0.0006200253847055137\n",
      "Epoch: 2550 | MAE Train loss: 0.0009449020144529641 | MAE Test loss: 0.001264637685380876\n",
      "Epoch: 2560 | MAE Train loss: 0.000595376652199775 | MAE Test loss: 0.0006200015777722001\n",
      "Epoch: 2570 | MAE Train loss: 0.0009448185446672142 | MAE Test loss: 0.0012645602691918612\n",
      "Epoch: 2580 | MAE Train loss: 0.000595376652199775 | MAE Test loss: 0.0006200015777722001\n",
      "Epoch: 2590 | MAE Train loss: 0.0009447604534216225 | MAE Test loss: 0.0012645006645470858\n",
      "Epoch: 2600 | MAE Train loss: 0.0005952917272225022 | MAE Test loss: 0.0006198823684826493\n",
      "Epoch: 2610 | MAE Train loss: 0.0009447269258089364 | MAE Test loss: 0.001264470862224698\n",
      "Epoch: 2620 | MAE Train loss: 0.0005952700739726424 | MAE Test loss: 0.0006198227638378739\n",
      "Epoch: 2630 | MAE Train loss: 0.0009446993353776634 | MAE Test loss: 0.0012644410599023104\n",
      "Epoch: 2640 | MAE Train loss: 0.0005952447536401451 | MAE Test loss: 0.0006197869661264122\n",
      "Epoch: 2650 | MAE Train loss: 0.0009446136537007987 | MAE Test loss: 0.0012643218506127596\n",
      "Epoch: 2660 | MAE Train loss: 0.000595210469327867 | MAE Test loss: 0.0006197631591930985\n",
      "Epoch: 2670 | MAE Train loss: 0.0009445898467674851 | MAE Test loss: 0.001264292048290372\n",
      "Epoch: 2680 | MAE Train loss: 0.0005951583152636886 | MAE Test loss: 0.0006196796894073486\n",
      "Epoch: 2690 | MAE Train loss: 0.0009445614996366203 | MAE Test loss: 0.0012642622459679842\n",
      "Epoch: 2700 | MAE Train loss: 0.0005951307830400765 | MAE Test loss: 0.0006196558242663741\n",
      "Epoch: 2710 | MAE Train loss: 0.0009444996831007302 | MAE Test loss: 0.0012641847133636475\n",
      "Epoch: 2720 | MAE Train loss: 0.0005950741469860077 | MAE Test loss: 0.0006195724126882851\n",
      "Epoch: 2730 | MAE Train loss: 0.0009444765746593475 | MAE Test loss: 0.0012641489738598466\n",
      "Epoch: 2740 | MAE Train loss: 0.0005950741469860077 | MAE Test loss: 0.000619608152192086\n",
      "Epoch: 2750 | MAE Train loss: 0.0009443804738111794 | MAE Test loss: 0.0012640893692150712\n",
      "Epoch: 2760 | MAE Train loss: 0.0005950555205345154 | MAE Test loss: 0.0006195545429363847\n",
      "Epoch: 2770 | MAE Train loss: 0.0009443573653697968 | MAE Test loss: 0.0012640655040740967\n",
      "Epoch: 2780 | MAE Train loss: 0.0005949698388576508 | MAE Test loss: 0.0006194412708282471\n",
      "Epoch: 2790 | MAE Train loss: 0.0009443283197470009 | MAE Test loss: 0.0012640297645702958\n",
      "Epoch: 2800 | MAE Train loss: 0.0005949698388576508 | MAE Test loss: 0.0006194412708282471\n",
      "Epoch: 2810 | MAE Train loss: 0.0009442664450034499 | MAE Test loss: 0.0012639581691473722\n",
      "Epoch: 2820 | MAE Train loss: 0.0005949698388576508 | MAE Test loss: 0.0006194412708282471\n",
      "Epoch: 2830 | MAE Train loss: 0.0009442411246709526 | MAE Test loss: 0.0012639224296435714\n",
      "Epoch: 2840 | MAE Train loss: 0.0005949087208136916 | MAE Test loss: 0.0006194353336468339\n",
      "Epoch: 2850 | MAE Train loss: 0.0009441942092962563 | MAE Test loss: 0.0012638687621802092\n",
      "Epoch: 2860 | MAE Train loss: 0.0005948506295681 | MAE Test loss: 0.0006193757290020585\n",
      "Epoch: 2870 | MAE Train loss: 0.0009441703441552818 | MAE Test loss: 0.001263821148313582\n",
      "Epoch: 2880 | MAE Train loss: 0.0005948163452558219 | MAE Test loss: 0.0006193459266796708\n",
      "Epoch: 2890 | MAE Train loss: 0.0009441703441552818 | MAE Test loss: 0.001263821148313582\n",
      "Epoch: 2900 | MAE Train loss: 0.0005947895115241408 | MAE Test loss: 0.0006193161243572831\n",
      "Epoch: 2910 | MAE Train loss: 0.000944085419178009 | MAE Test loss: 0.0012637019390240312\n",
      "Epoch: 2920 | MAE Train loss: 0.0005947895115241408 | MAE Test loss: 0.0006193161243572831\n",
      "Epoch: 2930 | MAE Train loss: 0.0009440563735552132 | MAE Test loss: 0.0012636840110644698\n",
      "Epoch: 2940 | MAE Train loss: 0.0005947418394498527 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 2950 | MAE Train loss: 0.0009440287831239402 | MAE Test loss: 0.0012636423343792558\n",
      "Epoch: 2960 | MAE Train loss: 0.0005947418394498527 | MAE Test loss: 0.0006192624568939209\n",
      "Epoch: 2970 | MAE Train loss: 0.0009439371642656624 | MAE Test loss: 0.0012635827297344804\n",
      "Epoch: 2980 | MAE Train loss: 0.0005947157624177635 | MAE Test loss: 0.0006192087894305587\n",
      "Epoch: 2990 | MAE Train loss: 0.0009439095738343894 | MAE Test loss: 0.001263564801774919\n",
      "Epoch: 3000 | MAE Train loss: 0.0005947157624177635 | MAE Test loss: 0.0006192087894305587\n",
      "Epoch: 3010 | MAE Train loss: 0.0009438887354917824 | MAE Test loss: 0.0012634933227673173\n",
      "Epoch: 3020 | MAE Train loss: 0.0005946852033957839 | MAE Test loss: 0.000619178987108171\n",
      "Epoch: 3030 | MAE Train loss: 0.0009438559645786881 | MAE Test loss: 0.0012634694576263428\n",
      "Epoch: 3040 | MAE Train loss: 0.0005946852033957839 | MAE Test loss: 0.000619178987108171\n",
      "Epoch: 3050 | MAE Train loss: 0.0009438276174478233 | MAE Test loss: 0.0012634455924853683\n",
      "Epoch: 3060 | MAE Train loss: 0.0005946330493316054 | MAE Test loss: 0.0006191015127114952\n",
      "Epoch: 3070 | MAE Train loss: 0.0009438276174478233 | MAE Test loss: 0.0012634455924853683\n",
      "Epoch: 3080 | MAE Train loss: 0.0005946062738075852 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 3090 | MAE Train loss: 0.0009437754633836448 | MAE Test loss: 0.0012633621226996183\n",
      "Epoch: 3100 | MAE Train loss: 0.0005946062738075852 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 3110 | MAE Train loss: 0.0009437158587388694 | MAE Test loss: 0.001263302518054843\n",
      "Epoch: 3120 | MAE Train loss: 0.0005946062738075852 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 3130 | MAE Train loss: 0.0009436875698156655 | MAE Test loss: 0.001263266778551042\n",
      "Epoch: 3140 | MAE Train loss: 0.0005945779266767204 | MAE Test loss: 0.0006190240383148193\n",
      "Epoch: 3150 | MAE Train loss: 0.000943656254094094 | MAE Test loss: 0.0012632429134100676\n",
      "Epoch: 3160 | MAE Train loss: 0.0005945488810539246 | MAE Test loss: 0.0006189942359924316\n",
      "Epoch: 3170 | MAE Train loss: 0.000943656254094094 | MAE Test loss: 0.0012632429134100676\n",
      "Epoch: 3180 | MAE Train loss: 0.0005944959702901542 | MAE Test loss: 0.0006189048290252686\n",
      "Epoch: 3190 | MAE Train loss: 0.000943656254094094 | MAE Test loss: 0.0012632429134100676\n",
      "Epoch: 3200 | MAE Train loss: 0.0005944959702901542 | MAE Test loss: 0.0006189048290252686\n",
      "Epoch: 3210 | MAE Train loss: 0.0009436264517717063 | MAE Test loss: 0.0012632191646844149\n",
      "Epoch: 3220 | MAE Train loss: 0.0005944706499576569 | MAE Test loss: 0.0006188750267028809\n",
      "Epoch: 3230 | MAE Train loss: 0.0009435966494493186 | MAE Test loss: 0.0012631833087652922\n",
      "Epoch: 3240 | MAE Train loss: 0.0005944460863247514 | MAE Test loss: 0.0006188154220581055\n",
      "Epoch: 3250 | MAE Train loss: 0.0009435966494493186 | MAE Test loss: 0.0012631833087652922\n",
      "Epoch: 3260 | MAE Train loss: 0.0005944140139035881 | MAE Test loss: 0.0006188154220581055\n",
      "Epoch: 3270 | MAE Train loss: 0.0009434774401597679 | MAE Test loss: 0.001263099955394864\n",
      "Epoch: 3280 | MAE Train loss: 0.0005944527802057564 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 3290 | MAE Train loss: 0.0009434491512365639 | MAE Test loss: 0.0012630640994757414\n",
      "Epoch: 3300 | MAE Train loss: 0.0005944527802057564 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 3310 | MAE Train loss: 0.0009434178355149925 | MAE Test loss: 0.0012630283599719405\n",
      "Epoch: 3320 | MAE Train loss: 0.0005944527802057564 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 3330 | MAE Train loss: 0.0009433880331926048 | MAE Test loss: 0.001263004494830966\n",
      "Epoch: 3340 | MAE Train loss: 0.0005944289150647819 | MAE Test loss: 0.0006187677499838173\n",
      "Epoch: 3350 | MAE Train loss: 0.0009433582308702171 | MAE Test loss: 0.0012629807461053133\n",
      "Epoch: 3360 | MAE Train loss: 0.0005944289150647819 | MAE Test loss: 0.0006187677499838173\n",
      "Epoch: 3370 | MAE Train loss: 0.0009433299419470131 | MAE Test loss: 0.0012629448901861906\n",
      "Epoch: 3380 | MAE Train loss: 0.0005944051081314683 | MAE Test loss: 0.0006187140825204551\n",
      "Epoch: 3390 | MAE Train loss: 0.0009433299419470131 | MAE Test loss: 0.0012629448901861906\n",
      "Epoch: 3400 | MAE Train loss: 0.0005943737924098969 | MAE Test loss: 0.0006186783430166543\n",
      "Epoch: 3410 | MAE Train loss: 0.0009432986262254417 | MAE Test loss: 0.0012629091506823897\n",
      "Epoch: 3420 | MAE Train loss: 0.0005943737924098969 | MAE Test loss: 0.0006186783430166543\n",
      "Epoch: 3430 | MAE Train loss: 0.0009432986262254417 | MAE Test loss: 0.0012629091506823897\n",
      "Epoch: 3440 | MAE Train loss: 0.0005943469586782157 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 3450 | MAE Train loss: 0.0009432748192921281 | MAE Test loss: 0.0012628734111785889\n",
      "Epoch: 3460 | MAE Train loss: 0.0005943469586782157 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 3470 | MAE Train loss: 0.0009432419901713729 | MAE Test loss: 0.0012628317344933748\n",
      "Epoch: 3480 | MAE Train loss: 0.0005943469586782157 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 3490 | MAE Train loss: 0.0009432152146473527 | MAE Test loss: 0.001262789941392839\n",
      "Epoch: 3500 | MAE Train loss: 0.0005943469586782157 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 3510 | MAE Train loss: 0.000943157821893692 | MAE Test loss: 0.0012627184623852372\n",
      "Epoch: 3520 | MAE Train loss: 0.0005943469586782157 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 3530 | MAE Train loss: 0.000943157821893692 | MAE Test loss: 0.0012627184623852372\n",
      "Epoch: 3540 | MAE Train loss: 0.0005943186697550118 | MAE Test loss: 0.0006186306709423661\n",
      "Epoch: 3550 | MAE Train loss: 0.000943157821893692 | MAE Test loss: 0.0012627184623852372\n",
      "Epoch: 3560 | MAE Train loss: 0.0005943186697550118 | MAE Test loss: 0.0006186306709423661\n",
      "Epoch: 3570 | MAE Train loss: 0.0009431295329704881 | MAE Test loss: 0.0012626827228814363\n",
      "Epoch: 3580 | MAE Train loss: 0.0005942940479144454 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3590 | MAE Train loss: 0.0009431011858396232 | MAE Test loss: 0.0012626588577404618\n",
      "Epoch: 3600 | MAE Train loss: 0.0005942940479144454 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3610 | MAE Train loss: 0.0009430684149265289 | MAE Test loss: 0.0012626349925994873\n",
      "Epoch: 3620 | MAE Train loss: 0.0005942940479144454 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3630 | MAE Train loss: 0.0009430684149265289 | MAE Test loss: 0.0012626349925994873\n",
      "Epoch: 3640 | MAE Train loss: 0.0005942665156908333 | MAE Test loss: 0.000618535268586129\n",
      "Epoch: 3650 | MAE Train loss: 0.0009430386126041412 | MAE Test loss: 0.0012625992530956864\n",
      "Epoch: 3660 | MAE Train loss: 0.0005942665156908333 | MAE Test loss: 0.000618535268586129\n",
      "Epoch: 3670 | MAE Train loss: 0.0009430103236809373 | MAE Test loss: 0.0012625635135918856\n",
      "Epoch: 3680 | MAE Train loss: 0.0005942665156908333 | MAE Test loss: 0.000618535268586129\n",
      "Epoch: 3690 | MAE Train loss: 0.0009429819765500724 | MAE Test loss: 0.001262539648450911\n",
      "Epoch: 3700 | MAE Train loss: 0.0005942665156908333 | MAE Test loss: 0.000618535268586129\n",
      "Epoch: 3710 | MAE Train loss: 0.0009429819765500724 | MAE Test loss: 0.001262539648450911\n",
      "Epoch: 3720 | MAE Train loss: 0.0005943000433035195 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3730 | MAE Train loss: 0.0009428113698959351 | MAE Test loss: 0.001262366771697998\n",
      "Epoch: 3740 | MAE Train loss: 0.0005943536525592208 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 3750 | MAE Train loss: 0.0009428113698959351 | MAE Test loss: 0.001262366771697998\n",
      "Epoch: 3760 | MAE Train loss: 0.0005943536525592208 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 3770 | MAE Train loss: 0.0009427837794646621 | MAE Test loss: 0.0012623369693756104\n",
      "Epoch: 3780 | MAE Train loss: 0.0005943536525592208 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 3790 | MAE Train loss: 0.0009427517652511597 | MAE Test loss: 0.0012623071670532227\n",
      "Epoch: 3800 | MAE Train loss: 0.0005943536525592208 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 3810 | MAE Train loss: 0.0009427517652511597 | MAE Test loss: 0.0012623608345165849\n",
      "Epoch: 3820 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3830 | MAE Train loss: 0.0009427197510376573 | MAE Test loss: 0.001262325095012784\n",
      "Epoch: 3840 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3850 | MAE Train loss: 0.0009427197510376573 | MAE Test loss: 0.001262325095012784\n",
      "Epoch: 3860 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3870 | MAE Train loss: 0.0009426921606063843 | MAE Test loss: 0.0012623012298718095\n",
      "Epoch: 3880 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3890 | MAE Train loss: 0.0009426645701751113 | MAE Test loss: 0.001262277364730835\n",
      "Epoch: 3900 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3910 | MAE Train loss: 0.0009426384931430221 | MAE Test loss: 0.0012622177600860596\n",
      "Epoch: 3920 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3930 | MAE Train loss: 0.0009426079923287034 | MAE Test loss: 0.0012621879577636719\n",
      "Epoch: 3940 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3950 | MAE Train loss: 0.0009426079923287034 | MAE Test loss: 0.0012621879577636719\n",
      "Epoch: 3960 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3970 | MAE Train loss: 0.0009425788884982467 | MAE Test loss: 0.0012621581554412842\n",
      "Epoch: 3980 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 3990 | MAE Train loss: 0.0009425788884982467 | MAE Test loss: 0.0012621581554412842\n",
      "Epoch: 4000 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 4010 | MAE Train loss: 0.000942520797252655 | MAE Test loss: 0.001262068748474121\n",
      "Epoch: 4020 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 4030 | MAE Train loss: 0.000942520797252655 | MAE Test loss: 0.001262068748474121\n",
      "Epoch: 4040 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 4050 | MAE Train loss: 0.0009424925083294511 | MAE Test loss: 0.0012620389461517334\n",
      "Epoch: 4060 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 4070 | MAE Train loss: 0.0009424925083294511 | MAE Test loss: 0.0012620389461517334\n",
      "Epoch: 4080 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 4090 | MAE Train loss: 0.0009424925083294511 | MAE Test loss: 0.0012620389461517334\n",
      "Epoch: 4100 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 4110 | MAE Train loss: 0.0009424671297892928 | MAE Test loss: 0.0012620091438293457\n",
      "Epoch: 4120 | MAE Train loss: 0.0005943126743659377 | MAE Test loss: 0.0006185710662975907\n",
      "Epoch: 4130 | MAE Train loss: 0.000942438084166497 | MAE Test loss: 0.0012619495391845703\n",
      "Epoch: 4140 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4150 | MAE Train loss: 0.000942438084166497 | MAE Test loss: 0.0012619495391845703\n",
      "Epoch: 4160 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4170 | MAE Train loss: 0.000942438084166497 | MAE Test loss: 0.0012619495391845703\n",
      "Epoch: 4180 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4190 | MAE Train loss: 0.000942409795243293 | MAE Test loss: 0.0012619197368621826\n",
      "Epoch: 4200 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4210 | MAE Train loss: 0.000942409795243293 | MAE Test loss: 0.0012619197368621826\n",
      "Epoch: 4220 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4230 | MAE Train loss: 0.000942409795243293 | MAE Test loss: 0.0012619197368621826\n",
      "Epoch: 4240 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4250 | MAE Train loss: 0.0009423583978787065 | MAE Test loss: 0.0012618422042578459\n",
      "Epoch: 4260 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4270 | MAE Train loss: 0.0009423583978787065 | MAE Test loss: 0.0012618422042578459\n",
      "Epoch: 4280 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4290 | MAE Train loss: 0.0009423583978787065 | MAE Test loss: 0.0012618422042578459\n",
      "Epoch: 4300 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4310 | MAE Train loss: 0.0009423308074474335 | MAE Test loss: 0.0012618005275726318\n",
      "Epoch: 4320 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4330 | MAE Train loss: 0.0009423308074474335 | MAE Test loss: 0.0012618005275726318\n",
      "Epoch: 4340 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4350 | MAE Train loss: 0.0009423308074474335 | MAE Test loss: 0.0012618005275726318\n",
      "Epoch: 4360 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4370 | MAE Train loss: 0.0009423017618246377 | MAE Test loss: 0.0012617825996130705\n",
      "Epoch: 4380 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4390 | MAE Train loss: 0.0009423017618246377 | MAE Test loss: 0.0012617825996130705\n",
      "Epoch: 4400 | MAE Train loss: 0.0005942858988419175 | MAE Test loss: 0.0006185531383380294\n",
      "Epoch: 4410 | MAE Train loss: 0.0009423017618246377 | MAE Test loss: 0.0012617825996130705\n",
      "Epoch: 4420 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4430 | MAE Train loss: 0.0009422712028026581 | MAE Test loss: 0.001261764788068831\n",
      "Epoch: 4440 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4450 | MAE Train loss: 0.0009422712028026581 | MAE Test loss: 0.001261764788068831\n",
      "Epoch: 4460 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4470 | MAE Train loss: 0.0009422712028026581 | MAE Test loss: 0.001261764788068831\n",
      "Epoch: 4480 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4490 | MAE Train loss: 0.0009422391885891557 | MAE Test loss: 0.001261722994968295\n",
      "Epoch: 4500 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4510 | MAE Train loss: 0.0009422391885891557 | MAE Test loss: 0.001261722994968295\n",
      "Epoch: 4520 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4530 | MAE Train loss: 0.0009422391885891557 | MAE Test loss: 0.001261722994968295\n",
      "Epoch: 4540 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4550 | MAE Train loss: 0.0009422115981578827 | MAE Test loss: 0.001261681318283081\n",
      "Epoch: 4560 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4570 | MAE Train loss: 0.0009422115981578827 | MAE Test loss: 0.001261681318283081\n",
      "Epoch: 4580 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4590 | MAE Train loss: 0.0009421892464160919 | MAE Test loss: 0.0012616455787792802\n",
      "Epoch: 4600 | MAE Train loss: 0.0005942583084106445 | MAE Test loss: 0.0006185054662637413\n",
      "Epoch: 4610 | MAE Train loss: 0.0009421281283721328 | MAE Test loss: 0.0012615859741345048\n",
      "Epoch: 4620 | MAE Train loss: 0.0005943775177001953 | MAE Test loss: 0.0006186544778756797\n",
      "Epoch: 4630 | MAE Train loss: 0.0009419508278369904 | MAE Test loss: 0.0012614071602001786\n",
      "Epoch: 4640 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4650 | MAE Train loss: 0.0009418584522791207 | MAE Test loss: 0.0012613475555554032\n",
      "Epoch: 4660 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4670 | MAE Train loss: 0.0009418584522791207 | MAE Test loss: 0.0012613475555554032\n",
      "Epoch: 4680 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4690 | MAE Train loss: 0.0009418584522791207 | MAE Test loss: 0.0012613475555554032\n",
      "Epoch: 4700 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4710 | MAE Train loss: 0.0009418316185474396 | MAE Test loss: 0.0012613177532330155\n",
      "Epoch: 4720 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4730 | MAE Train loss: 0.0009418316185474396 | MAE Test loss: 0.0012613177532330155\n",
      "Epoch: 4740 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4750 | MAE Train loss: 0.0009418316185474396 | MAE Test loss: 0.0012613177532330155\n",
      "Epoch: 4760 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4770 | MAE Train loss: 0.0009418316185474396 | MAE Test loss: 0.0012613177532330155\n",
      "Epoch: 4780 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4790 | MAE Train loss: 0.0009418316185474396 | MAE Test loss: 0.0012613177532330155\n",
      "Epoch: 4800 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4810 | MAE Train loss: 0.0009417727706022561 | MAE Test loss: 0.0012612283462658525\n",
      "Epoch: 4820 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4830 | MAE Train loss: 0.0009417727706022561 | MAE Test loss: 0.0012612283462658525\n",
      "Epoch: 4840 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4850 | MAE Train loss: 0.0009417727706022561 | MAE Test loss: 0.0012612283462658525\n",
      "Epoch: 4860 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4870 | MAE Train loss: 0.0009417727706022561 | MAE Test loss: 0.0012612283462658525\n",
      "Epoch: 4880 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4890 | MAE Train loss: 0.0009417727706022561 | MAE Test loss: 0.0012612283462658525\n",
      "Epoch: 4900 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4910 | MAE Train loss: 0.0009417451801709831 | MAE Test loss: 0.001261204481124878\n",
      "Epoch: 4920 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4930 | MAE Train loss: 0.0009417451801709831 | MAE Test loss: 0.001261204481124878\n",
      "Epoch: 4940 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4950 | MAE Train loss: 0.0009417451801709831 | MAE Test loss: 0.001261204481124878\n",
      "Epoch: 4960 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4970 | MAE Train loss: 0.0009417451801709831 | MAE Test loss: 0.001261204481124878\n",
      "Epoch: 4980 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 4990 | MAE Train loss: 0.0009417451801709831 | MAE Test loss: 0.001261204481124878\n",
      "Epoch: 5000 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 5010 | MAE Train loss: 0.0009417191031388938 | MAE Test loss: 0.0012611806159839034\n",
      "Epoch: 5020 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 5030 | MAE Train loss: 0.0009417191031388938 | MAE Test loss: 0.0012611806159839034\n",
      "Epoch: 5040 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 5050 | MAE Train loss: 0.0009417191031388938 | MAE Test loss: 0.0012611806159839034\n",
      "Epoch: 5060 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 5070 | MAE Train loss: 0.0009417191031388938 | MAE Test loss: 0.0012611806159839034\n",
      "Epoch: 5080 | MAE Train loss: 0.0005945280427113175 | MAE Test loss: 0.0006188034894876182\n",
      "Epoch: 5090 | MAE Train loss: 0.0009417191031388938 | MAE Test loss: 0.0012611806159839034\n",
      "Epoch: 5100 | MAE Train loss: 0.0005945012089796364 | MAE Test loss: 0.0006187498802319169\n",
      "Epoch: 5110 | MAE Train loss: 0.0009417191031388938 | MAE Test loss: 0.0012611806159839034\n",
      "Epoch: 5120 | MAE Train loss: 0.0005945012089796364 | MAE Test loss: 0.0006187498802319169\n",
      "Epoch: 5130 | MAE Train loss: 0.0009416535613127053 | MAE Test loss: 0.0012611091369763017\n",
      "Epoch: 5140 | MAE Train loss: 0.0005945310113020241 | MAE Test loss: 0.0006187736871652305\n",
      "Epoch: 5150 | MAE Train loss: 0.0009416535613127053 | MAE Test loss: 0.0012611091369763017\n",
      "Epoch: 5160 | MAE Train loss: 0.0005945310113020241 | MAE Test loss: 0.0006187736871652305\n",
      "Epoch: 5170 | MAE Train loss: 0.0009416535613127053 | MAE Test loss: 0.0012611091369763017\n",
      "Epoch: 5180 | MAE Train loss: 0.0005945310113020241 | MAE Test loss: 0.0006187736871652305\n",
      "Epoch: 5190 | MAE Train loss: 0.0009416535613127053 | MAE Test loss: 0.0012611091369763017\n",
      "Epoch: 5200 | MAE Train loss: 0.0005945310113020241 | MAE Test loss: 0.0006187736871652305\n",
      "Epoch: 5210 | MAE Train loss: 0.0009416535613127053 | MAE Test loss: 0.0012611091369763017\n",
      "Epoch: 5220 | MAE Train loss: 0.0005945310113020241 | MAE Test loss: 0.0006187736871652305\n",
      "Epoch: 5230 | MAE Train loss: 0.0009416535613127053 | MAE Test loss: 0.0012611091369763017\n",
      "Epoch: 5240 | MAE Train loss: 0.0005945310113020241 | MAE Test loss: 0.0006187736871652305\n",
      "Epoch: 5250 | MAE Train loss: 0.0009416535613127053 | MAE Test loss: 0.0012611091369763017\n",
      "Epoch: 5260 | MAE Train loss: 0.0005945310113020241 | MAE Test loss: 0.0006187736871652305\n",
      "Epoch: 5270 | MAE Train loss: 0.0009415998938493431 | MAE Test loss: 0.0012610614066943526\n",
      "Epoch: 5280 | MAE Train loss: 0.0005945593002252281 | MAE Test loss: 0.0006188094848766923\n",
      "Epoch: 5290 | MAE Train loss: 0.0009415998938493431 | MAE Test loss: 0.0012610614066943526\n",
      "Epoch: 5300 | MAE Train loss: 0.0005945593002252281 | MAE Test loss: 0.0006188094848766923\n",
      "Epoch: 5310 | MAE Train loss: 0.0009415998938493431 | MAE Test loss: 0.0012610614066943526\n",
      "Epoch: 5320 | MAE Train loss: 0.0005945593002252281 | MAE Test loss: 0.0006188094848766923\n",
      "Epoch: 5330 | MAE Train loss: 0.0009415998938493431 | MAE Test loss: 0.0012610614066943526\n",
      "Epoch: 5340 | MAE Train loss: 0.0005945593002252281 | MAE Test loss: 0.0006188094848766923\n",
      "Epoch: 5350 | MAE Train loss: 0.0009415998938493431 | MAE Test loss: 0.0012610614066943526\n",
      "Epoch: 5360 | MAE Train loss: 0.0005945593002252281 | MAE Test loss: 0.0006188094848766923\n",
      "Epoch: 5370 | MAE Train loss: 0.0009415998938493431 | MAE Test loss: 0.0012610614066943526\n",
      "Epoch: 5380 | MAE Train loss: 0.0005945593002252281 | MAE Test loss: 0.0006188094848766923\n",
      "Epoch: 5390 | MAE Train loss: 0.0009415998938493431 | MAE Test loss: 0.0012610614066943526\n",
      "Epoch: 5400 | MAE Train loss: 0.0005945593002252281 | MAE Test loss: 0.0006188094848766923\n",
      "Epoch: 5410 | MAE Train loss: 0.0009415998938493431 | MAE Test loss: 0.0012610614066943526\n",
      "Epoch: 5420 | MAE Train loss: 0.0005945593002252281 | MAE Test loss: 0.0006188094848766923\n",
      "Epoch: 5430 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5440 | MAE Train loss: 0.0005945906159467995 | MAE Test loss: 0.0006188452243804932\n",
      "Epoch: 5450 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5460 | MAE Train loss: 0.0005945906159467995 | MAE Test loss: 0.0006188452243804932\n",
      "Epoch: 5470 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5480 | MAE Train loss: 0.0005945906159467995 | MAE Test loss: 0.0006188452243804932\n",
      "Epoch: 5490 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5500 | MAE Train loss: 0.0005945906159467995 | MAE Test loss: 0.0006188452243804932\n",
      "Epoch: 5510 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5520 | MAE Train loss: 0.0005945682642050087 | MAE Test loss: 0.0006187856197357178\n",
      "Epoch: 5530 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5540 | MAE Train loss: 0.0005945682642050087 | MAE Test loss: 0.0006187856197357178\n",
      "Epoch: 5550 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5560 | MAE Train loss: 0.0005945682642050087 | MAE Test loss: 0.0006187856197357178\n",
      "Epoch: 5570 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5580 | MAE Train loss: 0.0005945682642050087 | MAE Test loss: 0.0006187856197357178\n",
      "Epoch: 5590 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5600 | MAE Train loss: 0.0005945682642050087 | MAE Test loss: 0.0006187856197357178\n",
      "Epoch: 5610 | MAE Train loss: 0.0009415343520231545 | MAE Test loss: 0.0012609899276867509\n",
      "Epoch: 5620 | MAE Train loss: 0.0005945682642050087 | MAE Test loss: 0.0006187856197357178\n",
      "Epoch: 5630 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5640 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5650 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5660 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5670 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5680 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5690 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5700 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5710 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5720 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5730 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5740 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5750 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5760 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5770 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5780 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5790 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5800 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5810 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5820 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5830 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5840 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5850 | MAE Train loss: 0.0009414806845597923 | MAE Test loss: 0.0012609421974048018\n",
      "Epoch: 5860 | MAE Train loss: 0.0005945980665273964 | MAE Test loss: 0.0006188213592395186\n",
      "Epoch: 5870 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 5880 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 5890 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 5900 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 5910 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 5920 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 5930 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 5940 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 5950 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 5960 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 5970 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 5980 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 5990 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6000 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6010 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6020 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6030 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6040 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6050 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6060 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6070 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6080 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6090 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6100 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6110 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6120 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6130 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6140 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6150 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6160 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6170 | MAE Train loss: 0.0009413875523023307 | MAE Test loss: 0.0012608468532562256\n",
      "Epoch: 6180 | MAE Train loss: 0.0005946561577729881 | MAE Test loss: 0.000618880963884294\n",
      "Epoch: 6190 | MAE Train loss: 0.0009413309162482619 | MAE Test loss: 0.0012607872486114502\n",
      "Epoch: 6200 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6210 | MAE Train loss: 0.0009412959334440529 | MAE Test loss: 0.0012607515091076493\n",
      "Epoch: 6220 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6230 | MAE Train loss: 0.0009412959334440529 | MAE Test loss: 0.0012607515091076493\n",
      "Epoch: 6240 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6250 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6260 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6270 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6280 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6290 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6300 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6310 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6320 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6330 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6340 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6350 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6360 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6370 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6380 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6390 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6400 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6410 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6420 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6430 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6440 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6450 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6460 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6470 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6480 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6490 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6500 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6510 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6520 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6530 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6540 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6550 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6560 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6570 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6580 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6590 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6600 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6610 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6620 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6630 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6640 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6650 | MAE Train loss: 0.000941274338401854 | MAE Test loss: 0.0012607037788257003\n",
      "Epoch: 6660 | MAE Train loss: 0.0005947172758169472 | MAE Test loss: 0.0006189405685290694\n",
      "Epoch: 6670 | MAE Train loss: 0.0009411819046363235 | MAE Test loss: 0.0012606143718585372\n",
      "Epoch: 6680 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6690 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6700 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6710 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6720 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6730 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6740 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6750 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6760 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6770 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6780 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6790 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6800 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6810 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6820 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6830 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6840 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6850 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6860 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6870 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6880 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6890 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6900 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6910 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6920 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6930 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6940 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6950 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6960 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6970 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 6980 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 6990 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7000 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7010 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7020 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7030 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7040 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7050 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7060 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7070 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7080 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7090 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7100 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7110 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7120 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7130 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7140 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7150 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7160 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7170 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7180 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7190 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7200 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7210 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7220 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7230 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7240 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7250 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7260 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7270 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7280 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7290 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7300 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7310 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7320 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7330 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7340 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7350 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7360 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7370 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7380 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7390 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7400 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7410 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7420 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7430 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7440 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7450 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7460 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7470 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7480 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7490 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7500 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7510 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7520 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7530 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7540 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7550 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7560 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7570 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7580 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7590 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7600 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7610 | MAE Train loss: 0.0009411312639713287 | MAE Test loss: 0.0012605547672137618\n",
      "Epoch: 7620 | MAE Train loss: 0.000594836485106498 | MAE Test loss: 0.0006190597778186202\n",
      "Epoch: 7630 | MAE Train loss: 0.0009410626953467727 | MAE Test loss: 0.0012604951625689864\n",
      "Epoch: 7640 | MAE Train loss: 0.0005949556943960488 | MAE Test loss: 0.000619178987108171\n",
      "Epoch: 7650 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7660 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7670 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7680 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7690 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7700 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7710 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7720 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7730 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7740 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7750 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7760 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7770 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7780 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7790 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7800 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7810 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7820 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7830 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7840 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7850 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7860 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7870 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7880 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7890 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7900 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7910 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7920 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7930 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7940 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7950 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7960 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7970 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 7980 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 7990 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8000 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8010 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8020 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8030 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8040 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8050 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8060 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8070 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8080 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8090 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8100 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8110 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8120 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8130 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8140 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8150 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8160 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8170 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8180 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8190 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8200 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8210 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8220 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8230 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8240 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8250 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8260 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8270 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8280 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8290 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8300 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8310 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8320 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8330 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8340 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8350 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8360 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8370 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8380 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8390 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8400 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8410 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8420 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8430 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8440 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8450 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8460 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8470 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8480 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8490 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8500 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8510 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8520 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8530 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8540 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8550 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8560 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8570 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8580 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8590 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8600 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8610 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8620 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8630 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8640 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8650 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8660 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8670 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8680 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8690 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8700 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8710 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8720 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8730 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8740 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8750 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8760 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8770 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8780 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8790 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8800 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8810 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8820 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8830 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8840 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8850 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8860 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8870 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8880 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8890 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8900 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8910 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8920 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8930 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8940 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8950 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8960 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8970 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 8980 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 8990 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9000 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9010 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9020 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9030 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9040 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9050 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9060 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9070 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9080 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9090 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9100 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9110 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9120 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9130 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9140 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9150 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9160 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9170 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9180 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9190 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9200 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9210 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9220 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9230 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9240 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9250 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9260 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9270 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9280 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9290 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9300 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9310 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9320 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9330 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9340 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9350 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9360 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9370 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9380 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9390 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9400 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9410 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9420 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9430 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9440 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9450 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9460 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9470 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9480 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9490 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9500 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9510 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9520 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9530 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9540 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9550 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9560 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9570 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9580 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9590 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9600 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9610 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9620 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9630 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9640 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9650 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9660 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9670 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9680 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9690 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9700 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9710 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9720 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9730 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9740 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9750 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9760 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9770 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9780 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9790 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9800 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9810 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9820 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9830 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9840 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9850 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9860 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9870 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9880 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9890 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9900 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9910 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9920 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9930 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9940 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9950 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9960 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9970 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n",
      "Epoch: 9980 | MAE Train loss: 0.0005950137856416404 | MAE Test loss: 0.0006192385917529464\n",
      "Epoch: 9990 | MAE Train loss: 0.0009409167105332017 | MAE Test loss: 0.001260346150957048\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "    y_pred = model_0(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_0(x_test)\n",
    "        test_loss = loss_fn(test_pred, y_test.type(torch.float))\n",
    "        if epoch % 10 ==0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train loss: {loss} | MAE Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23e9b57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x124b1e590>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176718a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
