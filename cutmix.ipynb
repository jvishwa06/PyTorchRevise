{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3610201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151830fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((96, 96)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    return transform(image)\n",
    "\n",
    "def show(img, title=\"\"):\n",
    "    npimg = img.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(np.clip(npimg, 0, 1))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def cutout(img, size=32):\n",
    "    img = img.clone()\n",
    "    h, w = img.shape[1], img.shape[2]\n",
    "    y = random.randint(size//2, h - size//2)\n",
    "    x = random.randint(size//2, w - size//2)\n",
    "    img[:, y-size//2:y+size//2, x-size//2:x+size//2] = 0\n",
    "    return img\n",
    "\n",
    "def mixup(img1, img2, label1, label2, alpha=0.4):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    mixed_img = lam * img1 + (1 - lam) * img2\n",
    "    return mixed_img, lam, label1, label2\n",
    "\n",
    "def cutmix(img1, img2, label1, label2):\n",
    "    img = img1.clone()\n",
    "    h, w = img.shape[1], img.shape[2]\n",
    "    cut_w, cut_h = w // 2, h // 2\n",
    "    x = random.randint(0, w - cut_w)\n",
    "    y = random.randint(0, h - cut_h)\n",
    "    img[:, y:y+cut_h, x:x+cut_w] = img2[:, y:y+cut_h, x:x+cut_w]\n",
    "    lam = 1 - (cut_w * cut_h / (h * w))\n",
    "    return img, lam, label1, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06be106",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path1 = 'img1.png'\n",
    "img_path2 = 'img2.png'\n",
    "\n",
    "\n",
    "label1, label2 = 3,2 \n",
    "img1 = load_image(img_path1)\n",
    "img2 = load_image(img_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8beca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_image = cutout(img_path1)\n",
    "show(cutout_image, f'cutout-image {label1}')\n",
    "\n",
    "mixup_img, lam, l1, l2 = mixup(img1, img2, label1, label2)\n",
    "show(cutout_image, f'mixup lambda={lam}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd15f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Load one CIFAR-10 image for demonstration\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "img_tensor, label = dataset[0]\n",
    "img = img_tensor.permute(1, 2, 0).numpy() * 255\n",
    "img = img.astype(np.uint8)\n",
    "\n",
    "# Resize for better visualization\n",
    "img = cv2.resize(img, (224, 224))\n",
    "\n",
    "# Utility to visualize augmentation\n",
    "def show_augmented(title, aug_img):\n",
    "    plt.imshow(aug_img)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Albumentations: Advanced augmentations\n",
    "augmentations = {\n",
    "    \"Blur\": A.Blur(blur_limit=7, p=1.0),\n",
    "    \"GridDistortion\": A.GridDistortion(p=1.0),\n",
    "    \"ElasticTransform\": A.ElasticTransform(p=1.0),\n",
    "    \"CLAHE\": A.CLAHE(p=1.0),\n",
    "    \"RandomBrightnessContrast\": A.RandomBrightnessContrast(p=1.0),\n",
    "    \"CoarseDropout\": A.CoarseDropout(max_height=40, max_width=40, min_height=20, min_width=20, p=1.0),\n",
    "    \"RandomCrop\": A.RandomCrop(width=160, height=160, p=1.0),\n",
    "    \"GaussianBlur\": A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "    \"HueSaturationValue\": A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1.0),\n",
    "    \"MotionBlur\": A.MotionBlur(blur_limit=7, p=1.0)\n",
    "}\n",
    "\n",
    "# Visualize each Albumentations augmentation\n",
    "for name, aug in augmentations.items():\n",
    "    aug_img = aug(image=img)['image']\n",
    "    show_augmented(name, aug_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858204a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open webcam and make real-time predictions\n",
    "cap = cv2.VideoCapture(0)  # Open the default webcam (use 0 for default, or change to the desired camera index)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "else:\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Failed to capture frame.\")\n",
    "                break\n",
    "\n",
    "            # Convert frame to RGB (YOLO model expects RGB images)\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Perform prediction\n",
    "            results = model.predict(source=rgb_frame, show=False, conf=0.5)\n",
    "\n",
    "            # Visualize predictions on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            # Display the frame with predictions\n",
    "            cv2.imshow(\"YOLO Predictions\", annotated_frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc3e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161e49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a5262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
